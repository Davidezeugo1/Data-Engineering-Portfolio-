# ğŸ§± Data Engineering Portfolio

ğŸ‘‹ Hi, I'm [Your Name] â€” a data engineer passionate about building scalable data systems and automation.

This portfolio contains a collection of end-to-end data engineering projects using modern tools like Airflow, Spark, Kafka, and Docker.

---

## ğŸ“‚ Projects Overview

| Project | Description | Stack |
|----------|--------------|--------|
| [Weather ETL](./project_1_api_pipeline) | Daily API â†’ MySQL ETL pipeline with Airflow | Airflow, MySQL, Python |
| [NYC Taxi Data Lake](./project_2_batch_spark) | Batch processing pipeline using Spark and Parquet | Spark, Parquet, MySQL |
| [Crypto Streaming](./project_3_streaming) | Real-time data pipeline with Kafka and Spark Streaming | Kafka, Spark, MySQL |
| [Retail Data Platform](./project_4_end_to_end) | Complete end-to-end data platform | Airflow, Spark, Docker, Twingate |

---

## âš™ï¸ Tools & Technologies

- **Languages:** Python, SQL
- **Orchestration:** Apache Airflow
- **Processing:** Apache Spark, PySpark, Pandas
- **Streaming:** Apache Kafka
- **Storage:** MySQL, Parquet, S3/MinIO
- **Infrastructure:** Docker, Twingate
- **Visualization:** Grafana, Streamlit

---

## ğŸ“š Learning Goals
- Master end-to-end pipeline design
- Implement data quality checks (Great Expectations)
- Automate data flows with CI/CD
- Optimize for scalability and maintainability


